{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic using Logistic Regression\n",
    "\n",
    "This week we will be building a logistic regression classifier to predict survival on the titanic.   \n",
    "\n",
    "My model will use the independent variables sex and age to predict the dependent variable survived.  There are many other variables in the dataset that you could and should use, that will be your assignment for the week.   (More on that later)\n",
    "\n",
    "###Data Prep\n",
    "First, I will start with some data prep to get my data ready to be used in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading the data from the disk into memory\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just a reminder, here are all the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avgM_Age_1 = df.Age[(df.Sex == 'male') & (df.Pclass == 1)].mean()\n",
    "avgM_Age_2 = df.Age[(df.Sex == 'male') & (df.Pclass == 2)].mean()\n",
    "avgM_Age_3 = df.Age[(df.Sex == 'male') & (df.Pclass == 3)].mean()\n",
    "\n",
    "avgF_Age_1 = df.Age[(df.Sex == 'female') & (df.Pclass == 1)].mean()\n",
    "avgF_Age_2 = df.Age[(df.Sex == 'female') & (df.Pclass == 2)].mean()\n",
    "avgF_Age_3 = df.Age[(df.Sex == 'female') & (df.Pclass == 3)].mean()\n",
    "\n",
    "avgF_Age_1\n",
    "df.Age = df.Age.fillna(value=0)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assignAge(Sex,Age,Pclass):\n",
    "    if(Age == 0):\n",
    "    \n",
    "        if(Sex == 'male'):\n",
    "            if(Pclass == 1):\n",
    "                 return avgM_Age_1\n",
    "            if(Pclass == 2):\n",
    "                 return avgM_Age_2\n",
    "            if(Pclass == 3):\n",
    "                 return avgM_Age_3\n",
    "\n",
    "#df.Age = df[(df['Sex'] == 'male') & (df['Pclass'] == 1)].fillna(value=avgM_Age_1)\n",
    "#df.Age = df[(df['Sex'] == 'male') & (df['Pclass'] == 2)].fillna(value=avgM_Age_2)\n",
    "#df.Age = df[(df['Sex'] == 'male') & (df['Pclass'] == 3)].fillna(value=avgM_Age_3)\n",
    "\n",
    "        else: #then sex = female\n",
    "            if(Pclass == 1):\n",
    "                 return avgF_Age_1\n",
    "            if(Pclass == 2):\n",
    "                 return avgF_Age_2\n",
    "            if(Pclass == 3):\n",
    "                 return avgF_Age_3\n",
    "    \n",
    "#df.Age = df[(df['Sex'] == 'female') & (df['Pclass'] == 1)].fillna(value=avgF_Age_1)\n",
    "#df.Age = df[(df['Sex'] == 'female') & (df['Pclass'] == 2)].fillna(value=avgF_Age_2)\n",
    "#df.Age = df[(df['Sex'] == 'female') & (df['Pclass'] == 3)].fillna(value=avgF_Age_3)\n",
    "\n",
    "    else:\n",
    "        return Age;\n",
    "\n",
    "\n",
    "#avgM_Age = df.Age[df['Sex'] == 'male'].mean()\n",
    "#avgF_Age = df.Age[df['Sex'] == 'female'].mean()\n",
    "\n",
    "#df.Age = df.Age[df['Sex'] == 'male'].fillna(value=avgM_Age)\n",
    "#df.Age = df.Age[df['Sex'] == 'female'].fillna(value=avgF_Age)\n",
    "\n",
    "#avgAge = df.Age.mean()\n",
    "#df.Age = df.Age.fillna(value=avgAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df[df.Age.isnull()]\n",
    "df['Age'] = df.apply(lambda row: assignAge(row['Sex'], row['Age'], row['Pclass']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I'm going to create a new dataframe and put only the variables I'm going to be using into it.\n",
    "X = pd.DataFrame()\n",
    "X['sex'] = df['Sex']\n",
    "X['age'] = df['Age']\n",
    "X['Pclass'] = df['Pclass']\n",
    "X['Pclass1'] = df['Pclass']\n",
    "X['Pclass2'] = df['Pclass']\n",
    "X['Embarked'] = df['Embarked']\n",
    "X['EmbarkedS'] = df['Embarked']\n",
    "X['EmbarkedQ'] = df['Embarked']\n",
    "X['survived'] = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I'm going to drop missing values.   That's probably NOT the best strategy, but it's usually good to start simple and \n",
    "#build complexity as you go.\n",
    "#X = X.dropna(axis=0)\n",
    "#X['age'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#survived will be my dependent variable, y.   I'll assign it to y and remove it from X\n",
    "y = X['survived']\n",
    "X = X.drop(['survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     female  male\n",
       "0       0.0   1.0\n",
       "1       1.0   0.0\n",
       "2       1.0   0.0\n",
       "3       1.0   0.0\n",
       "4       0.0   1.0\n",
       "5       0.0   1.0\n",
       "6       0.0   1.0\n",
       "7       0.0   1.0\n",
       "8       1.0   0.0\n",
       "9       1.0   0.0\n",
       "10      1.0   0.0\n",
       "11      1.0   0.0\n",
       "12      0.0   1.0\n",
       "13      0.0   1.0\n",
       "14      1.0   0.0\n",
       "15      1.0   0.0\n",
       "16      0.0   1.0\n",
       "17      0.0   1.0\n",
       "18      1.0   0.0\n",
       "19      1.0   0.0\n",
       "20      0.0   1.0\n",
       "21      0.0   1.0\n",
       "22      1.0   0.0\n",
       "23      0.0   1.0\n",
       "24      1.0   0.0\n",
       "25      1.0   0.0\n",
       "26      0.0   1.0\n",
       "27      0.0   1.0\n",
       "28      1.0   0.0\n",
       "29      0.0   1.0\n",
       "..      ...   ...\n",
       "861     0.0   1.0\n",
       "862     1.0   0.0\n",
       "863     1.0   0.0\n",
       "864     0.0   1.0\n",
       "865     1.0   0.0\n",
       "866     1.0   0.0\n",
       "867     0.0   1.0\n",
       "868     0.0   1.0\n",
       "869     0.0   1.0\n",
       "870     0.0   1.0\n",
       "871     1.0   0.0\n",
       "872     0.0   1.0\n",
       "873     0.0   1.0\n",
       "874     1.0   0.0\n",
       "875     1.0   0.0\n",
       "876     0.0   1.0\n",
       "877     0.0   1.0\n",
       "878     0.0   1.0\n",
       "879     1.0   0.0\n",
       "880     1.0   0.0\n",
       "881     0.0   1.0\n",
       "882     1.0   0.0\n",
       "883     0.0   1.0\n",
       "884     0.0   1.0\n",
       "885     1.0   0.0\n",
       "886     0.0   1.0\n",
       "887     1.0   0.0\n",
       "888     1.0   0.0\n",
       "889     0.0   1.0\n",
       "890     0.0   1.0\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to handle Sex such that it's categorical, for logistic regression.\n",
    "# Currently it's a string\n",
    "#refer back to last week's lecture if you forget why we're doing this\n",
    "\n",
    "#We can use pandas get_dummies to implement one hot encoding.\n",
    "pd.get_dummies(X.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IMPORTANT! get_dummies returns an indicator variable for each category.\n",
    "#Refering back to my talk on encoding variables, it's important to drop one category\n",
    "#Otherwise you'll have two perfectly colinear variables.   \n",
    "\n",
    "#Here, since I only have two variables it's easy, I'll just take one, and reassign it to sex\n",
    "#so now Sex becomes female = 1, male = 0\n",
    "X['sex'] = pd.get_dummies(X.sex)['female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(X.Pclass)\n",
    "pd.get_dummies(X.Pclass2)\n",
    "X['Pclass1'] = pd.get_dummies(X.Pclass)[1]\n",
    "X['Pclass2'] = pd.get_dummies(X.Pclass)[2]\n",
    "X = X.drop(['Pclass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>Pclass1</th>\n",
       "      <th>Pclass2</th>\n",
       "      <th>EmbarkedS</th>\n",
       "      <th>EmbarkedQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.352413</td>\n",
       "      <td>29.318643</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.722783</td>\n",
       "      <td>0.086420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.281103</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.447876</td>\n",
       "      <td>0.281141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.507589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sex         age     Pclass1     Pclass2   EmbarkedS   EmbarkedQ\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean     0.352413   29.318643    0.242424    0.206510    0.722783    0.086420\n",
       "std      0.477990   13.281103    0.428790    0.405028    0.447876    0.281141\n",
       "min      0.000000    0.420000    0.000000    0.000000    0.000000    0.000000\n",
       "25%      0.000000   21.750000    0.000000    0.000000    0.000000    0.000000\n",
       "50%      0.000000   26.507589    0.000000    0.000000    1.000000    0.000000\n",
       "75%      1.000000   36.000000    0.000000    0.000000    1.000000    0.000000\n",
       "max      1.000000   80.000000    1.000000    1.000000    1.000000    1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(X.Embarked)\n",
    "X['EmbarkedS'] = pd.get_dummies(X.Embarked)['S']\n",
    "X['EmbarkedQ'] = pd.get_dummies(X.Embarked)['Q']\n",
    "X = X.drop(['Embarked'], axis=1)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remember to scale our features, as with linear regression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X= scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "At this point I have a test and train set defined.  I will use train to train my model and test to see how accurate the model is.\n",
    "\n",
    "There's one problem with that though.   Lets say my model is right 70% of the time.   Is that good?  Maybe?   \n",
    "\n",
    "I'm going to build a simple 'base rate' model to compare my logistic model to, so we can see if our logistic model is useful or not.  \n",
    "\n",
    "Then, I'll build my logistic model.\n",
    "\n",
    "\n",
    "####Base Rate Model\n",
    "For my baserate model, I'm going to predict that everyone dies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function looks for females in the test set and returns 1, survived, otherwise it returns 0\n",
    "def base_rate_model(X):\n",
    "    y = np.zeros(X.shape[0])\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base rate accuracy is 0.59\n"
     ]
    }
   ],
   "source": [
    "#how accurate is my base rate model?\n",
    "y_base_rate = base_rate_model(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Base rate accuracy is %2.2f\" % accuracy_score(y_test, y_base_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our base model is 61% correct, lets see if logistic can beat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic accuracy is 0.80\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic accuracy is %2.2f\" % accuracy_score(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Our base model wasn't very good, but it looked better than it was because of class imbalance.  There are many more 0s than 1s in our dataset, so if we just guess 0 we can 'cheat.'\n",
    "\n",
    "A better metric for binary classifer comparisons is AUC or area under the curve. \n",
    "\n",
    "Closely related is [precision and recall](http://scikit-learn.org/stable/auto_examples/plot_precision_recall.html).\n",
    "\n",
    "Precision is the fraction of correctly identified examples of a class (ratio of true positives to all positives).\n",
    "\n",
    "Recall is the fraction of observastions classified in that class that was correctly classified.  \n",
    "\n",
    "Think of fishing with a net for tuna.   \n",
    "*  If our net is very precise, and has high recall it will catch any and all tuna and ONLY tuna.\n",
    "*  If our net is very precise, but has low recall then we might catch one tuna, but most will escape.\n",
    "*  If our net is low precision, but has high recall, then we might catch tuna, but also any other fish around\n",
    "*  If our net is low precision, and low recall, then we should probably give up fishing.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Base Model---\n",
      "Base Rate AUC = 0.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      1.00      0.74       105\n",
      "          1       0.00      0.00      0.00        74\n",
      "\n",
      "avg / total       0.34      0.59      0.43       179\n",
      "\n",
      "\n",
      "\n",
      "---Logistic Model---\n",
      "Logistic AUC = 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdmurphy\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (\"---Base Model---\")\n",
    "#base rate AUC\n",
    "base_roc_auc = roc_auc_score(y_test, base_rate_model(X_test))\n",
    "print (\"Base Rate AUC = %2.2f\" % base_roc_auc)\n",
    "print (classification_report(y_test,base_rate_model(X_test) ))\n",
    "print (\"\\n\\n---Logistic Model---\")\n",
    "#logistic AUC\n",
    "logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "print (\"Logistic AUC = %2.2f\" % logit_roc_auc)\n",
    "#print classification_report(y_test, model.predict(X_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa9af470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
